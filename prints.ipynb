{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L2Vll7psnctA",
    "outputId": "45829300-2487-41c8-cd30-812ee44abe4e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "from io import StringIO \n",
    "\n",
    "CPBP_MODEL_PATH = 'MiniCPBP/cpbpnewnew.jar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "504cTysbJb9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Marginals Manager\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "#from signal import signal, SIGPIPE, SIG_DFL\n",
    "import json\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "class Marginals():\n",
    "    def __init__(self,length, note_max, composition, jar_path,rules=[1 for i in range(12)]):\n",
    "        self.composition = copy.deepcopy(composition)\n",
    "        self.jar_path    = jar_path\n",
    "        self.length      = length\n",
    "        self.note_max    = note_max\n",
    "        self.done = False\n",
    "        self.marginals= {str(j):0 for j in range(0,note_max)}\n",
    "        self.expected = {i:0 for i in range(30)}\n",
    "        self.violations = [0 for i in range(12)]\n",
    "        self.unsat = False\n",
    "        self.write_ready = False\n",
    "        self.rules = rules\n",
    "        self.deleted = False\n",
    "        jar_array = ['java', '-cp',jar_path,'minicpbp.examples.Counterpoint_Soft']\n",
    "        jar_array.extend([str(i) for i in composition])\n",
    "        jar_array.extend([str(i) for i in rules])\n",
    "        jar_array += [str(length)]\n",
    "        p = Popen(jar_array, stdin=PIPE, stdout=PIPE, stderr=STDOUT)\n",
    "        self.p = p\n",
    "        process_msg = self.get_process_msg()\n",
    "        try: \n",
    "            self.unsat = bool(process_msg['sat_exception'])\n",
    "        except:\n",
    "            print('Exception occured...')\n",
    "            print(process_msg)\n",
    "        self.done  = bool(process_msg['done'])\n",
    "        self.expected  = process_msg['expected']\n",
    "        self.expected_marginals  = process_msg['E_marginals']\n",
    "        self.violations = process_msg['violations']\n",
    "        while((not self.write_ready) and (not self.unsat) and (not self.done)):\n",
    "            garbage_msg = self.get_process_msg()\n",
    "            self.write_ready = bool(garbage_msg['read'])\n",
    "            self.done = self.done or bool(garbage_msg['done'])\n",
    "            self.unsat = self.unsat or bool(garbage_msg['sat_exception'])\n",
    "        #if((process_msg['done'] +  process_msg['sat_exception'] == 0)):\n",
    "        #    self.expected  = process_msg['expected']\n",
    "            #self.marginals  = process_msg['marginals'][str(len(self.composition))]\n",
    "        #self.violations = process_msg['violations']\n",
    "\n",
    "    def step(self,note):\n",
    "        if((self.done + self.unsat == 0) and self.write_ready and (len(self.composition)<self.length)):\n",
    "            self.send_msg(note)\n",
    "            process_msg = self.get_process_msg()\n",
    "            if(process_msg['expected']>=0):\n",
    "                self.expected = process_msg['expected']\n",
    "            if(len(process_msg['violations'].keys())>0):\n",
    "                self.violations = process_msg['violations']\n",
    "            if(len(process_msg['E_marginals'].keys())>0):\n",
    "                self.expected_marginals  = process_msg['E_marginals']\n",
    "\n",
    "            while((not self.write_ready) and (not self.unsat) and (not self.done)):\n",
    "                garbage_msg = self.get_process_msg()\n",
    "                self.write_ready = bool(garbage_msg['read'])\n",
    "                self.done = self.done or bool(garbage_msg['done'])\n",
    "                self.unsat = self.unsat or bool(garbage_msg['sat_exception'])\n",
    "            self.composition += [note]\n",
    "\n",
    "            self.done      = self.done or bool(process_msg['done'])\n",
    "            self.unsat     = self.unsat or bool(process_msg['sat_exception'])            \n",
    "            #print(\"done: \",process_msg['done'],\"unsat: \",process_msg['sat_exception'],\" len: \",len(self.composition),\" violations:\",self.violations)\n",
    "    \n",
    "    def get_marginals(self):\n",
    "        expected_marginals = {str(j):0 for j in range(0,300)}\n",
    "        if(self.unsat):\n",
    "            print('Unsat...')\n",
    "            return expected_marginals\n",
    "        for k in self.expected_marginals.keys():\n",
    "            expected_marginals[k] = self.expected_marginals[k]\n",
    "        return expected_marginals\n",
    "    \n",
    "    def get_expected(self):\n",
    "        if(self.unsat):\n",
    "            #print('Unsat error!')\n",
    "            #print(self.composition)\n",
    "            return 500\n",
    "        return self.expected\n",
    "\n",
    "    def get_violations(self):\n",
    "        return self.violations\n",
    "\n",
    "    def send_msg(self,note):\n",
    "        if(self.done or self.unsat or (not self.write_ready)):\n",
    "            return\n",
    "        else:\n",
    "            p = self.p\n",
    "            p.stdin.write(bytes(str(note) + '\\n', encoding='utf-8'))\n",
    "            p.stdin.flush()\n",
    "            self.write_ready = False\n",
    "\n",
    "    def get_process_msg(self):\n",
    "        if(self.done or self.write_ready or self.unsat):\n",
    "            return {}\n",
    "        p = self.p\n",
    "        msg = (p.stdout.readline()).decode('utf-8')\n",
    "        try:\n",
    "            msg_json = json.loads(msg)\n",
    "        except:\n",
    "            print(\"Failed to convert to json...\")\n",
    "            return {}\n",
    "        return msg_json\n",
    "    \n",
    "    #Returns the key for the current composition and rules\n",
    "    def key(self):\n",
    "        key_ = '_'.join([str(n) for n in self.composition])\n",
    "        rules_key = 'r'.join([str(r) for r in self.rules])\n",
    "        return key_+'='+rules_key\n",
    "    def delete(self):\n",
    "        #del self.composition\n",
    "        #del self.expected\n",
    "        #del self.violations\n",
    "        if(not self.deleted):\n",
    "            parent_pid = self.p.pid\n",
    "            parent = psutil.Process(parent_pid)\n",
    "            for child in parent.children(recursive=True):  # or parent.children() for recursive=False\n",
    "                child.kill()\n",
    "                parent.kill()\n",
    "            del self.p\n",
    "            self.deleted = True\n",
    "        #del self\n",
    "\n",
    "#Controller/worker manager \n",
    "class Marginals_Manager():\n",
    "    def __init__(self,length, note_max, composition, jar_path):\n",
    "        self.length = length\n",
    "        self.Ms = [] #workers of the class Marginals()\n",
    "        self.jar_path=jar_path\n",
    "        self.length = length\n",
    "        self.note_max = note_max\n",
    "        \n",
    "    def compute_counterpoint(self, notes, rules=[1 for i in range(12)], mode='expected'):\n",
    "        #Clearing memory\n",
    "        if(len(self.Ms)>5):\n",
    "            self.clear()\n",
    "            print('Cleared!')\n",
    "        notes_ = [str(note) for note in notes]\n",
    "        rules_key = 'r'.join([str(r) for r in rules])\n",
    "        key = '_'.join(notes_)\n",
    "        key_prev = '_'.join(notes_[:-1])\n",
    "        key = key + '=' + rules_key\n",
    "        key_prev = key_prev + '=' + rules_key\n",
    "        M = get_M(self.Ms,key)\n",
    "        M_prev = get_M(self.Ms,key_prev)\n",
    "        if(not M == None):\n",
    "            if(mode=='expected'):\n",
    "                return M.get_expected()\n",
    "            elif(mode=='violations'):\n",
    "                return M.get_violations()\n",
    "            elif(mode=='marginals'):\n",
    "                return M.get_marginals()\n",
    "        elif(not M_prev == None): \n",
    "            M_prev.step(notes[-1])\n",
    "            if(mode=='expected'):\n",
    "                return M_prev.get_expected()\n",
    "            elif(mode=='violations'):\n",
    "                return M_prev.get_violations()\n",
    "            elif(mode=='marginals'):\n",
    "                return M_prev.get_marginals()\n",
    "        else: \n",
    "            #print('couldnt find ',notes)\n",
    "            M = Marginals(self.length, self.note_max, notes, self.jar_path,rules=rules)\n",
    "            self.Ms += [M]\n",
    "            if(mode=='expected'):\n",
    "                return M.get_expected()\n",
    "            elif(mode=='violations'):\n",
    "                return M.get_violations()\n",
    "            elif(mode=='marginals'):\n",
    "                return M.get_marginals()\n",
    "\n",
    "    def clear(self):\n",
    "        for i in range(len(self.Ms)):\n",
    "            self.Ms[i].delete()\n",
    "        self.Ms.clear()\n",
    "        \n",
    "#Finds the M in Ms with the right key\n",
    "def get_M(Ms,key):\n",
    "    for i in range(len(Ms)):\n",
    "        if(Ms[i].key()==key):\n",
    "            return Ms[i]\n",
    "    return None\n",
    "#Removes M from Ms with the right key\n",
    "def remove_M(Ms,key):\n",
    "    for i in range(len(Ms)):\n",
    "        if(Ms[i].key()==key):\n",
    "            Ms.remove(Ms[i])\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, h1_in_size, h1_state_size, length, n_labels, n_layers, loss_mode='NLL', time_skip = True,\n",
    "                SAVE_PATH = 'saved_models/',MODEL_NAME='LSTM_fast'):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        super(LSTM,self).__init__()\n",
    "        #Basic attributes\n",
    "        self.time_skip     = time_skip\n",
    "        self.input_size    = input_size\n",
    "        self.h1_in_size    = h1_in_size\n",
    "        self.h1_state_size = h1_state_size\n",
    "        self.n_labels      = n_labels\n",
    "        self.length        = length\n",
    "        self.n_layers      = n_layers\n",
    "        self.h_0          = torch.zeros((n_layers,1,self.h1_state_size),device=self.device,dtype=torch.float64)\n",
    "        self.c_0          = torch.zeros((n_layers,1,self.h1_state_size),device=self.device,dtype=torch.float64)\n",
    "        #Initializing network gates\n",
    "        self.lstm        = nn.LSTM(self.h1_in_size, self.h1_state_size,self.n_layers,dtype=torch.float64,device=self.device,dropout=0.0)\n",
    "        self.lstm.batch_first=True\n",
    "        \n",
    "        self.dense_in      = nn.Linear(self.input_size, self.h1_in_size,device=self.device,dtype=torch.float64)\n",
    "        self.dense_1a      = nn.Linear(self.h1_in_size,self.h1_in_size ,device=self.device,dtype=torch.float64)\n",
    "        self.dense_1b      = nn.Linear(self.h1_in_size,self.h1_in_size ,device=self.device,dtype=torch.float64)\n",
    "        self.dense_1c      = nn.Linear(self.h1_in_size,self.h1_in_size ,device=self.device,dtype=torch.float64)\n",
    "        \n",
    "        self.dense_2a      = nn.Linear(self.h1_state_size,self.h1_state_size,device=self.device,dtype=torch.float64)\n",
    "        self.dense_2b      = nn.Linear(self.h1_state_size,self.h1_state_size,device=self.device,dtype=torch.float64)\n",
    "        self.dense_2c      = nn.Linear(self.h1_state_size,self.h1_state_size,device=self.device,dtype=torch.float64)\n",
    "        self.dense_out     = nn.Linear(self.h1_state_size,self.n_labels     ,device=self.device,dtype=torch.float64)\n",
    "        \n",
    "        self.bn_in = nn.BatchNorm1d(self.h1_in_size,device=self.device,dtype=torch.float64)\n",
    "        self.bn_1a = nn.BatchNorm1d(self.h1_in_size,device=self.device,dtype=torch.float64)\n",
    "        self.bn_1b = nn.BatchNorm1d(self.h1_in_size,device=self.device,dtype=torch.float64)\n",
    "        self.bn_1c = nn.BatchNorm1d(self.h1_in_size,device=self.device,dtype=torch.float64)\n",
    "        \n",
    "        self.bn_2a = nn.BatchNorm1d(self.h1_state_size,device=self.device,dtype=torch.float64)\n",
    "        self.bn_2b = nn.BatchNorm1d(self.h1_state_size,device=self.device,dtype=torch.float64)\n",
    "        self.bn_2c = nn.BatchNorm1d(self.h1_state_size,device=self.device,dtype=torch.float64)\n",
    "        self.bn_out= nn.BatchNorm1d(self.n_labels     ,device=self.device,dtype=torch.float64)\n",
    "        \n",
    "        self.relu          = nn.ReLU()\n",
    "        self.activation    = nn.LogSoftmax(dim=2)\n",
    "        self.activation_generate = nn.LogSoftmax(dim=1)\n",
    "        self.SAVE_PATH = SAVE_PATH\n",
    "        self.MODEL_NAME = MODEL_NAME\n",
    "        self.accuracy = 0\n",
    "        \n",
    "    #Initialize h1_0 and c1_0\n",
    "    def initialize_hiddens(self,batch_size):\n",
    "        h1_0 = torch.tile(self.h_0,(1,batch_size,1))\n",
    "        c1_0 = torch.tile(self.c_0,(1,batch_size,1))\n",
    "        h1_0.requires_grad = False\n",
    "        c1_0.requires_grad = False\n",
    "        return h1_0.to(self.device),c1_0.to(self.device)\n",
    "    \n",
    "    def forward(self,X,eval_mode=False):\n",
    "        bt_ends = X[:,-1,0]\n",
    "        bt_ends = bt_ends.type(torch.int64)\n",
    "        X = X[:,:-1,:]\n",
    "        \n",
    "        X = X.type(torch.float64)\n",
    "        if(eval_mode):\n",
    "            self.eval()\n",
    "        else:\n",
    "            self.train()\n",
    "        batch_size = X.shape[0]\n",
    "        length     = X.shape[1]\n",
    "        input_size = X.shape[2]\n",
    "        h1_0,c1_0  = self.initialize_hiddens(batch_size)\n",
    "        Y = self.dense_in(X)\n",
    "        Y=self.bn_in(Y.view(batch_size,-1,length))        \n",
    "        Y=self.relu(Y.view(batch_size,length,-1))\n",
    "        Y = self.dense_1a(Y)\n",
    "        Y=self.bn_1a(Y.view(batch_size,-1,length))\n",
    "        Y=self.relu(Y.view(batch_size,length,-1))\n",
    "        Y = self.dense_1b(Y)\n",
    "        Y=self.bn_1b(Y.view(batch_size,-1,length))\n",
    "        Y=self.relu(Y.view(batch_size,length,-1))\n",
    "        Y = self.dense_1c(Y)\n",
    "        Y=self.bn_1c(Y.view(batch_size,-1,length))\n",
    "        Y=self.relu(Y.view(batch_size,length,-1))\n",
    "        Y, (h, c) = self.lstm(Y,(h1_0,c1_0))\n",
    "        h_0 = torch.zeros((Y.shape[0],1,Y.shape[2]),device=device,dtype=torch.float64)\n",
    "        Y = torch.cat((h_0,Y),1)\n",
    "        Y_=torch.zeros((Y.shape[0],Y.shape[2]),device=device,dtype=torch.float64)\n",
    "        for i0 in range(Y.shape[0]):\n",
    "            Y_[i0,:] = Y[i0,bt_ends[i0].item(),:]\n",
    "        Y = Y_\n",
    "        Y = self.dense_2a(Y)\n",
    "        Y=self.bn_2a(Y.view(batch_size,-1))\n",
    "        Y=self.relu(Y.view(batch_size,-1))\n",
    "        Y = self.dense_2b(Y)\n",
    "        Y=self.bn_2b(Y.view(batch_size,-1))\n",
    "        Y=self.relu(Y.view(batch_size,-1))\n",
    "        Y = self.dense_2c(Y)\n",
    "        Y=self.bn_2c(Y.view(batch_size,-1))\n",
    "        Y=self.relu(Y.view(batch_size,-1))\n",
    "        Y = self.dense_out(Y)\n",
    "\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "GsQ8v0_nqcvE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title DQN (simple E)\n",
    "class Tuner_Env:\n",
    "    def __init__(self, length):\n",
    "        #self.lstm = lstm\n",
    "        self.CPBP_MODEL_PATH=CPBP_MODEL_PATH\n",
    "        self.cpbp = Marginals_Manager(length, 30, [], CPBP_MODEL_PATH)\n",
    "        self.composition = []\n",
    "        self.length = length\n",
    "        self.violations  = {str(i):0 for i in range(12)}\n",
    "        self.last_E  = self.cpbp.compute_counterpoint([], mode='expected')\n",
    "        self.last_vs = 0\n",
    "        self.max_length=40\n",
    "    def get_reward(self):\n",
    "        vs   = self.get_violations_sum()\n",
    "        r_vs = -(vs-self.last_vs)\n",
    "        self.last_vs=vs\n",
    "        #print(self.composition)\n",
    "        #print(self.last_vs)\n",
    "        cur_E = self.cpbp.compute_counterpoint(self.composition, mode='expected')\n",
    "        r_e = -(cur_E-self.last_E)\n",
    "        self.last_E = cur_E\n",
    "\n",
    "        eps = 1e-45\n",
    "        r_5  = eps\n",
    "        r_15 = eps\n",
    "        r_25 = eps\n",
    "        r_35 = eps\n",
    "        r_45 = eps\n",
    "\n",
    "        expected_marginals = self.cpbp.compute_counterpoint(self.composition, mode='marginals')\n",
    "        for k in expected_marginals.keys():\n",
    "            if(int(k)<=45):\n",
    "                r_45 += expected_marginals[k]\n",
    "            \n",
    "            if(int(k)<=35):\n",
    "                r_35 += expected_marginals[k]\n",
    "            \n",
    "            if(int(k)<=25):\n",
    "                r_25 += expected_marginals[k]\n",
    "\n",
    "            if(int(k)<=15):\n",
    "                r_15 += expected_marginals[k]\n",
    "            \n",
    "            if(int(k)<=5):\n",
    "                r_5 += expected_marginals[k]\n",
    "\n",
    "        #return 0, float(r_e + r_vs)\n",
    "        #return 0, float(r_vs)\n",
    "        return 0, float(r_vs + r_e + np.log(r_5)/500 + np.log(r_15)/500 + np.log(r_25)/500 + np.log(r_35)/500 + np.log(r_45)/500)\n",
    "        #return 0, float(np.log(r_5)/500 + np.log(r_15)/500 + np.log(r_25)/500 + np.log(r_35)/500 + np.log(r_45)/500 + r_e)\n",
    "    def step(self,action):\n",
    "        if(len(self.composition)<self.length):\n",
    "            assert(not action == None)\n",
    "            self.composition += [action]\n",
    "            r_lstm, r_cpbp = self.get_reward()\n",
    "        else:\n",
    "            r_lstm, r_cpbp = 0,0\n",
    "        terminated = len(self.composition)==self.length\n",
    "        return self.get_observation(), r_lstm + r_cpbp, terminated\n",
    "\n",
    "    def get_observation(self):\n",
    "        obs = []\n",
    "        for i in range(len(self.composition)):\n",
    "            onehot = np.zeros(31)\n",
    "            onehot[self.composition[i]] = 1\n",
    "            onehot[30] = len(self.composition) >= self.length-1\n",
    "            obs += [list(onehot)]\n",
    "        for i in range(self.max_length - len(self.composition)):\n",
    "            onehot = np.zeros(31)\n",
    "            obs += [list(onehot)]\n",
    "        \n",
    "        return obs+[[len(self.composition)]*31]\n",
    "\n",
    "    def get_violations(self):\n",
    "        return self.cpbp.compute_counterpoint(self.composition, mode='violations')\n",
    "\n",
    "    def get_violations_sum(self, selected_vk = -1):\n",
    "        violations = self.get_violations()\n",
    "        v_sum = 0\n",
    "        for v_k in violations.keys():\n",
    "            if((selected_vk == -1) or v_k == str(selected_vk)):\n",
    "                v_sum+=violations[v_k]\n",
    "        return v_sum\n",
    "\n",
    "    def reset(self):\n",
    "        self.composition = []\n",
    "        self.violations  = {str(i):0 for i in range(12)}\n",
    "        self.last_E  = self.cpbp.compute_counterpoint([], mode='expected')\n",
    "        self.last_vs = self.get_violations_sum()\n",
    "        self.cpbp.clear()\n",
    "        self.cpbp = Marginals_Manager(self.length, 30, [], CPBP_MODEL_PATH)\n",
    "        return self.get_observation()\n",
    "    \n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.LSTM = LSTM(n_actions+1, n_actions+1, 100, 32, n_actions, 2, time_skip=False)\n",
    "        \n",
    "    def forward(self, x, eval_mode=True):\n",
    "        x = self.LSTM(x,eval_mode=eval_mode)\n",
    "        return x\n",
    "    \n",
    "class Agent():\n",
    "    def __init__(self,length=32, batch_size=128,gamma=0.99,eps_start=0.9,eps_end=0.05,eps_decay=1000,tau=0.005,lr=0.0001, memory_size=10000, name=\"\",SAVE_PATH=\"DQN_models/\"):\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.GAMMA = gamma\n",
    "        self.EPS_START = eps_start\n",
    "        self.EPS_END = eps_end\n",
    "        self.EPS_DECAY = eps_decay\n",
    "        self.TAU = tau\n",
    "        self.LR = lr\n",
    "        self.n_actions = 30\n",
    "        # Get the number of state observations\n",
    "        self.policy_net = DQN(self.n_actions).to(device)\n",
    "        self.target_net = DQN(self.n_actions).to(device)\n",
    "        self.optimizer = optim.AdamW(self.policy_net.parameters(), lr=self.LR, amsgrad=True)\n",
    "        self.memory = ReplayMemory(memory_size)\n",
    "        self.steps_done = 0\n",
    "        self.rand_actions = list(np.arange(30))\n",
    "        self.device = device\n",
    "        self.name = name\n",
    "        self.save_path = SAVE_PATH\n",
    "        self.eval_lengths = [length, length+10, length+30, length+50]\n",
    "        self.run_results = [{str(i):[] for i in list(range(12))+['total']}, {k:{str(i):[] for i in list(range(12))+['total']} for k in self.eval_lengths},'agent: '+self.name]\n",
    "        try:\n",
    "            self.load()\n",
    "        except:\n",
    "            print(\"failed to load\")\n",
    "    def select_action(self,state,eval_mode = False):\n",
    "        sample = random.random()\n",
    "        eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * \\\n",
    "            math.exp(-1. * self.steps_done / self.EPS_DECAY)\n",
    "        self.steps_done += 1\n",
    "        if((sample > eps_threshold) or eval_mode):\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return the largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                return self.policy_net(state).max(1)[1].view(1, 1)\n",
    "        else:\n",
    "            return torch.tensor([[random.choice(self.rand_actions)]], device=device, dtype=torch.long)\n",
    "    \n",
    "    def optimize_model(self):\n",
    "        if len(self.memory) < self.BATCH_SIZE:\n",
    "            return\n",
    "        transitions = self.memory.sample(self.BATCH_SIZE)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                    if s is not None])\n",
    "        state_batch  = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        \n",
    "        state_action_values = self.policy_net(state_batch, eval_mode=False).gather(1, action_batch)\n",
    "        next_state_values = torch.zeros(self.BATCH_SIZE, device=self.device, dtype=torch.float64)\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1)[0]\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (next_state_values * self.GAMMA) + reward_batch\n",
    "        # Compute Huber loss\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # In-place gradient clipping\n",
    "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 5)\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def load(self):\n",
    "        try:\n",
    "            self.policy_net.load_state_dict(torch.load(self.save_path+self.name+\"_policy\"))\n",
    "            self.target_net.load_state_dict(torch.load(self.save_path+self.name+\"_target\"))\n",
    "        except:\n",
    "            print(\"failed to load DQN\")\n",
    "        with open(self.save_path+self.name+\"_meta.pkl\", 'rb') as file:\n",
    "            meta = pickle.load(file)\n",
    "            self.steps_done = meta[\"steps_done\"]\n",
    "            self.run_results = meta[\"run_results\"]\n",
    "            \n",
    "    def save(self):\n",
    "        torch.save(self.policy_net.state_dict(), self.save_path+self.name+\"_policy\")\n",
    "        torch.save(self.target_net.state_dict(), self.save_path+self.name+\"_target\")\n",
    "        meta = {\"steps_done\":self.steps_done, \"run_results\":self.run_results}\n",
    "        with open(self.save_path+self.name+\"_meta.pkl\", 'wb') as file:\n",
    "            pickle.dump(meta, file)\n",
    "            \n",
    "    def eval_model(self, eval_length = 32):\n",
    "        eval_env = Tuner_Env(eval_length)\n",
    "        viols = {str(i):0 for i in range(12)}\n",
    "        viols[\"total\"] = 0\n",
    "        for i in range(10):\n",
    "            state = eval_env.reset()\n",
    "            state = torch.tensor(state, dtype=torch.float64, device=device).unsqueeze(0)\n",
    "            for j in range(eval_length):\n",
    "                action = agent.select_action(state,eval_mode = True)\n",
    "                observation, reward, terminated = eval_env.step(action.item())\n",
    "                state = torch.tensor(observation, dtype=torch.float64, device=device).unsqueeze(0)\n",
    "            viols[\"total\"] += eval_env.get_violations_sum()\n",
    "            for k in range(12):\n",
    "                viols[str(k)] += eval_env.get_violations_sum(selected_vk=k)\n",
    "        eval_env.reset()\n",
    "        viols[\"total\"]/=10\n",
    "        for k in range(12):\n",
    "            viols[str(k)]/=10\n",
    "        return viols\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prune_num(name):\n",
    "    if('1' in name.split('-')):\n",
    "        name = name.split('-')\n",
    "        name.remove('1')\n",
    "        name = '-'.join(name)\n",
    "    return name\n",
    "def prune_LSTM(name):\n",
    "    if('LSTM' in name.split('-')):\n",
    "        name = name.split('-')\n",
    "        name.remove('LSTM')\n",
    "        name = '-'.join(name)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_violations(ep_lists,eval_period=15, k=1, agent_names=[]):\n",
    "    an = copy.deepcopy(agent_names)\n",
    "    for i in range(len(an)):\n",
    "        if('1' in an[i].split('-')):\n",
    "            an[i] = prune_num(an[i])\n",
    "        if('LSTM' in an[i].split('-')):\n",
    "            an[i] = prune_LSTM(an[i])\n",
    "    agent_names = set()\n",
    "    for i in range(len(an)):\n",
    "        agent_names.add(an[i])\n",
    "    agent_names = list(agent_names)\n",
    "    cmap = get_cmap_string(domain=agent_names)\n",
    "    length = 35\n",
    "    eval_lengths = [length-20, length, length+55]\n",
    "    plot_keys = [\"total\"]+[str(i) for i in range(12)]\n",
    "    versions  = ['new', 'old']\n",
    "    violation_names_new = {\"total\":\"total\",\n",
    "                      \"0\":\"naturalNotes\",\n",
    "                      \"1\":\"bFlat\",\n",
    "                      \"2\":\"noRepeat\",\n",
    "                      \"3\":\"stepwiseDescentToFinal\",\n",
    "                      \"4\":\"tonicEnds\",\n",
    "                      \"5\":\"avoidSixths\",\n",
    "                      \"6\":\"skipStepsSequence\",\n",
    "                      \"7\":\"skipStepRatio\",\n",
    "                      \"8\":\"coverModalRange\",\n",
    "                      \"9\":\"characteristicModalSkips\",\n",
    "                      \"10\":\"skipStepSequence\",\n",
    "                      \"11\":\"tritonOutlines\"}\n",
    "    violation_names_old = {\"total\":\"total\",\n",
    "                      \"0\":\"naturalNotes\",\n",
    "                      \"1\":\"intervals\",\n",
    "                      \"2\":\"tritonOutlines\",\n",
    "                      \"3\":\"tonicEnds\",\n",
    "                      \"4\":\"stepwiseDescentToFinal\",\n",
    "                      \"5\":\"repeats\",\n",
    "                      \"6\":\"coverModalRange\",\n",
    "                      \"7\":\"characteristicModalSkips\",\n",
    "                      \"8\":\"skipStepsRatio\",\n",
    "                      \"9\":\"sixths\",\n",
    "                      \"10\":\"skipStepsSequence\",\n",
    "                      \"11\":\"bFlat\"}\n",
    "    \n",
    "    highlighted_labels = [\n",
    "                        #\"V.dE.m-C-100DQN-PR\", \"V.dE.m-C-100DQN-LSTM-PR\",\n",
    "                        \"V.dE-C-100DQN-PR\", \"V.dE-C-100DQN-LSTM-PR\",\n",
    "                        #\"V.m-C-100DQN-PR\",  \"V.m-C-100DQN-LSTM-PR\",\n",
    "                        \"V-D(normed)-64DQN-shorts-PR\",\"V-D(normed)-64DQN-shorts-LSTM-PR\",\n",
    "                        #\"V-C-100DQN-PR\",\"V-C-100DQN-LSTM-PR\",\n",
    "                        #\"dE.m-C-100DQN-PR\",\"dE.m-C-100DQN-LSTM-PR\"\n",
    "                         ]\n",
    "    for ver in versions:\n",
    "        for el in eval_lengths:\n",
    "            for pk in plot_keys:\n",
    "                if(ver=='new'):\n",
    "                    violation_names = violation_names_new\n",
    "                else:\n",
    "                    violation_names = violation_names_old\n",
    "                bar_names_color = []\n",
    "                bar_names_label = []\n",
    "                bar_vals  = []\n",
    "                bar_stds  = []\n",
    "                if(not pk == \"total\"):# and (not pk ==\"3\") and  (not pk ==\"4\")):\n",
    "                    ...\n",
    "                    #continue\n",
    "                ymax=-1\n",
    "                ymin=999\n",
    "                for ep in ep_lists:\n",
    "                    vs = []\n",
    "                    evals = []\n",
    "                    stds  = []\n",
    "                    ep_viols = ep[0]\n",
    "                    ep_evals = ep[1][ver][el]\n",
    "                    ep_label = prune_num(ep[2][7:])\n",
    "                    lastx = 0\n",
    "                    for i in range(len(ep_evals[pk])):\n",
    "                        if(ep_evals[pk][i][0]>9000 or ep_evals[pk][i][0]<200):\n",
    "                            ...\n",
    "                            #continue\n",
    "                        evals += [[ep_evals[pk][i][0],ep_evals[pk][i][1]]]#-(ep_evals[\"3\"][i][1]+ep_evals[\"4\"][i][1])]]\n",
    "                        lastx = ep_evals[pk][i][0]\n",
    "                        lasty = ep_evals[pk][i][1]\n",
    "                        laststd=ep_evals[pk][i][-1]\n",
    "                        stds  += [ep_evals[pk][i][-1]]\n",
    "                    evals = np.array(evals)\n",
    "                    al = 1\n",
    "                    dots = \"-.\"\n",
    "                    if(\"LSTM\" in ep_label.split('-')):# and (not ep_label==\"no-marginals\")):\n",
    "                        dots = \"-\"\n",
    "                    if(ep_label in highlighted_labels):\n",
    "                        ...\n",
    "                        al = 1\n",
    "                    ys_hi = evals[:,1] + stds\n",
    "                    ys_lo = evals[:,1] - stds\n",
    "                    if(ys_hi.max()>ymax):\n",
    "                        ymax=ys_hi.max()\n",
    "                    if(ys_lo.min()<ymin):\n",
    "                        ymin=ys_lo.min()\n",
    "                    spl_hi = make_interp_spline(evals[:,0], ys_hi, k=k)\n",
    "                    spl_lo = make_interp_spline(evals[:,0], ys_lo, k=k)\n",
    "                    spl    = make_interp_spline(evals[:,0], evals[:,1], k=k)\n",
    "                    xsmooth = np.linspace(evals[:,0].min(), evals[:,0].max(), 200) \n",
    "                    y_smooth_hi = spl_hi(xsmooth)\n",
    "                    y_smooth_lo = spl_lo(xsmooth)\n",
    "                    y_smooth_   = spl(xsmooth)\n",
    "                    symb = \"\"\n",
    "                    lsymb = \"\"\n",
    "                    if(\"LSTM\" in ep_label.split(\"-\")):\n",
    "                        symb = \"s\"\n",
    "                        lsymb=\"--\"\n",
    "                    else:\n",
    "                        lsymb=\"-\"\n",
    "                        symb = \"o\"\n",
    "                    ep_label  = ep_label.split('-')\n",
    "                    ep_label_ = copy.deepcopy(ep_label)\n",
    "                    real_label = []\n",
    "                    if('dV' in ep_label):\n",
    "                        real_label += ['ΔV']\n",
    "                    elif('dV.m' in ep_label_):\n",
    "                        real_label += ['ΔV.m']\n",
    "                    elif('dV.dE' in ep_label_):\n",
    "                        real_label += ['ΔV.ΔE']\n",
    "                    elif('dV.dE(normalized)' in ep_label_):\n",
    "                        real_label += ['ΔV.ΔE.normalized']\n",
    "                    elif('dE.m' in ep_label_):\n",
    "                        real_label += ['ΔE.m']\n",
    "                    elif('dV.dE.m' in ep_label_):\n",
    "                        real_label += ['ΔV.ΔE.m']\n",
    "                    if('A' in ep_label_):\n",
    "                        real_label += ['[A]']\n",
    "                    elif('B' in ep_label_):\n",
    "                        real_label += ['[B]']\n",
    "                    elif('B(more.features)' in ep_label_):\n",
    "                        real_label += ['[B]']\n",
    "                    elif('B(noised)' in ep_label_):\n",
    "                        real_label += ['[B.noised]']\n",
    "                    elif('B.2' in ep_label_):\n",
    "                        real_label += ['[B.lessFeatures]']\n",
    "                    elif('C' in ep_label_):\n",
    "                        real_label += ['[C]']\n",
    "                    if('0.92m' in ep_label_):\n",
    "                        real_label += ['0.92m']\n",
    "                    if('0.75m' in ep_label_):\n",
    "                        real_label += ['0.75m']\n",
    "                    if('attention' in ep_label_):\n",
    "                        real_label += ['attention']\n",
    "                    if('transformer' in ep_label_):\n",
    "                        real_label += ['transformer']\n",
    "                    if('NEW' in ep_label_):\n",
    "                        real_label += ['NEW']\n",
    "                    if('OLD' in ep_label_):\n",
    "                        real_label += ['OLD']\n",
    "                    ep_label_= '-'.join(real_label[:])\n",
    "                    if('LSTM' in ep_label):\n",
    "                        ep_label.remove('LSTM')\n",
    "                        ep_label = '-'.join(ep_label)\n",
    "                        bar_names_color += [ep_label]\n",
    "                        bar_vals  += [lasty]\n",
    "                        bar_stds  += [laststd]\n",
    "                        bar_names_label += [ep_label_[:]]\n",
    "                        plt.fill_between(xsmooth,y_smooth_hi,y_smooth_lo,color=cmap(ep_label),alpha=al/10,linewidth=0.0)\n",
    "                        plt.plot(xsmooth, y_smooth_, lsymb, color=cmap(ep_label),alpha=al, linewidth=1.2)\n",
    "                    else:\n",
    "                        ep_label = '-'.join(ep_label)\n",
    "                        bar_names_color += [ep_label]\n",
    "                        bar_vals  += [lasty]\n",
    "                        bar_stds  += [laststd]\n",
    "                        bar_names_label += [ep_label_]\n",
    "                        plt.fill_between(xsmooth,y_smooth_hi,y_smooth_lo,color=cmap(ep_label),alpha=al/5,linewidth=0.0,label=ep_label_)\n",
    "                        plt.plot(xsmooth, y_smooth_, lsymb, color=cmap(ep_label),alpha=al, linewidth=1)\n",
    "\n",
    "                fz = 7\n",
    "                plt.title('['+ver+']'+ ' length ' +str(el) +' rule: '+ violation_names[pk],fontsize=fz+2)\n",
    "                plt.xlabel('n. episodes',fontsize=fz)\n",
    "                plt.ylabel('n. violations',fontsize=fz)\n",
    "                leg=plt.legend(prop={'size': 7}, markerscale=2.5)\n",
    "                for lh in leg.legendHandles: \n",
    "                    lh.set_alpha(1)\n",
    "                fig = plt.gcf()\n",
    "                fig.set_size_inches(4,2.5)\n",
    "                plt.xticks(np.arange(100,6001,650), fontsize=fz)\n",
    "                ymin -= 5\n",
    "                ymin = max(0,ymin)\n",
    "                #ymin=0\n",
    "                ymax += ymax*0.1\n",
    "                ax = plt.gca()\n",
    "                ax.set_facecolor((1, 1, 1))\n",
    "                #ymin = 0\n",
    "                #print((ymin,ymax))\n",
    "                #print(np.arange(int(ymin/5)*5, int(ymax/5)*5+10,((ymax-ymin)/10)))\n",
    "                plt.yticks(np.arange(int(ymin/5)*5, int(ymax/5)*5+5,((ymax+5-ymin)/15)), fontsize=fz)\n",
    "                plt.grid(linestyle = '--', linewidth = 0.5)\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                ymax = np.max(bar_vals) + 35\n",
    "                ymin = 0#np.min(bar_vals)\n",
    "                y_pos = 1*np.arange(len(bar_names_color))\n",
    "                patterns = []\n",
    "                for ipos in range(len(y_pos)):\n",
    "                    if(ipos%2==0):\n",
    "                        patterns += [\"\"]\n",
    "                    else:\n",
    "                        patterns += [\"O\"]\n",
    "                y_pos_ = np.arange(0,len(bar_names_color),2,dtype=float)\n",
    "                y_pos_ += (y_pos[1]-y_pos[0])/2\n",
    "                for ipos in range(len(y_pos)):\n",
    "                    if(ipos%2==0):\n",
    "                        plt.bar(y_pos[ipos], bar_vals[ipos],color=cmap(bar_names_color[ipos]),yerr=bar_stds[ipos], capsize=2,hatch=patterns[ipos], label=bar_names_label[ipos])\n",
    "                    else:\n",
    "                        plt.bar(y_pos[ipos], bar_vals[ipos],color=cmap(bar_names_color[ipos]),yerr=bar_stds[ipos], capsize=2,hatch=patterns[ipos])\n",
    "                bar_names_label_2s = [bar_names_label[2*i] for i in range(int(len(bar_names_label)/2))]\n",
    "                plt.xticks(y_pos_, [\"\" for b in bar_names_label_2s], fontsize=fz)#,rotation = 15, ha=\"right\",rotation_mode='anchor')\n",
    "                #leg=plt.legend(prop={'size': 7}, markerscale=2.5)\n",
    "                plt.yticks(np.arange(int(ymin/5)*5, int(ymax/5)*5+10,((ymax-ymin)/8)), fontsize=fz)\n",
    "                for i in range(len(bar_names_label)):\n",
    "                    plt.text(x = y_pos[i]-0.65 , y = bar_vals[i]+bar_stds[i]+0.75, s = bar_vals[i], size = 8)\n",
    "                #for i in range(len(y_pos_)):\n",
    "                #    plt.text(x = y_pos_[i] - len(bar_names_label[2*i])/10, y = -7, s = bar_names_label[2*i], size = 8)\n",
    "                fig = plt.gcf()\n",
    "                fig.set_size_inches(6,5.2)\n",
    "                #leg=plt.legend(prop={'size': 7}, markerscale=2.5)\n",
    "                plt.title(\"Final number of violations for instances of length \"+str(el), fontsize=fz+2)\n",
    "                plt.ylabel('n. violations',fontsize=fz)\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "    rnn_plots = 0\n",
    "    for ep in ep_lists:\n",
    "        ep_label = ep[2][7:]\n",
    "        if(not \"LSTM\" in ep_label.split('-')):\n",
    "            continue\n",
    "        #print(ep_label)\n",
    "        rnn_plots += 1\n",
    "        ys_avg = []\n",
    "        ys_std = []\n",
    "        ys_hi  = []\n",
    "        ys_lo  = []\n",
    "        xs     = []\n",
    "        k=25\n",
    "        for i in range(0,len(ep[0]['rnn_score']),50):\n",
    "            #print([[i,k*np.mean(ep[0]['rnn_score'][max(0,i-5):min(len(ep[0]['rnn_score'])-1,i+5)])]])\n",
    "            if(i<100):\n",
    "                continue\n",
    "            xs     += [i]\n",
    "            ys_avg += [k*np.mean(ep[0]['rnn_score'][max(0,i-25):min(len(ep[0]['rnn_score'])-1,i+25)])]\n",
    "            ys_std += [k*np.std(ep[0]['rnn_score'][max(0,i-25):min(len(ep[0]['rnn_score'])-1,i+25)])]\n",
    "        ys_avg = np.array(ys_avg)\n",
    "        ys_std = np.array(ys_std)\n",
    "        xs     = np.array(xs)\n",
    "        #plt.plot(np.arange(len(ep[0]['rnn_score'])),np.array(ep[0]['rnn_score'])*k, linewidth=0.5,alpha=0.25,color=cmap(ep_label))\n",
    "        #plt.plot(ys_avg[:,0],ys_avg[:,1], linewidth=1.0,color=cmap(ep_label),alpha=0.5)\n",
    "        #plt.plot(ys_avg[:,0],ys_avg[:,1], 'o', color=cmap(ep_label),alpha=1.0, markersize=1.0,label=ep_label)\n",
    "        #plt.errorbar(ys_avg[:,0], ys_avg[:,1], yerr=ys_std, color=cmap(ep_label),alpha=1.0,linewidth=0,elinewidth=1.0,capsize=0)\n",
    "        plt.legend()\n",
    "        fz = 7\n",
    "        \n",
    "        ys_hi = ys_avg + ys_std\n",
    "        ys_lo = ys_avg - ys_std\n",
    "        #print(ys_avg)\n",
    "        spl_hi = make_interp_spline(xs, ys_hi, k=1)\n",
    "        \n",
    "        spl_lo = make_interp_spline(xs, ys_lo, k=1)\n",
    "        spl    = make_interp_spline(xs, ys_avg,k=1)\n",
    "        xsmooth = np.linspace(xs.min(), xs.max(), 200) \n",
    "        y_smooth_hi = spl_hi(xsmooth)\n",
    "        y_smooth_lo = spl_lo(xsmooth)\n",
    "        y_smooth_   = spl(xsmooth)\n",
    "        \n",
    "        \n",
    "        ep_label = ep_label.split('-')\n",
    "        ep_label.remove('LSTM')\n",
    "        ep_label_ = copy.deepcopy(ep_label)\n",
    "        real_label = []\n",
    "        if('dV' in ep_label_):\n",
    "            real_label += ['ΔV']\n",
    "        elif('dV.m' in ep_label_):\n",
    "            real_label += ['ΔV.m']\n",
    "        elif('dV.dE' in ep_label_):\n",
    "            real_label += ['ΔV.ΔE']\n",
    "        elif('dV.dE(normalized)' in ep_label_):\n",
    "            real_label += ['ΔV.ΔE.normalized']\n",
    "        elif('dE.m' in ep_label_):\n",
    "            real_label += ['ΔE.m']\n",
    "        elif('dV.dE.m' in ep_label_):\n",
    "            real_label += ['ΔV.ΔE.m']\n",
    "        if('A' in ep_label_):\n",
    "            real_label += ['[A]']\n",
    "        elif('B' in ep_label_):\n",
    "            real_label += ['[B]']\n",
    "        elif('B(normed)' in ep_label_):\n",
    "            real_label += ['[B.normed]']\n",
    "        elif('B(noised)' in ep_label_):\n",
    "            real_label += ['[B.noised]']\n",
    "        elif('B.2' in ep_label_):\n",
    "            real_label += ['[B.lessFeatures]']\n",
    "        elif('C' in ep_label_):\n",
    "            real_label += ['[C]']\n",
    "        ep_label_= '-'.join(real_label)\n",
    "        ep_label = '-'.join(ep_label)\n",
    "        al =0.95\n",
    "        if(ep_label in highlighted_labels):\n",
    "            al=0.95\n",
    "        \n",
    "        plt.fill_between(xsmooth,y_smooth_hi,y_smooth_lo,color=cmap(ep_label),alpha=al/5,linewidth=0.0, label=ep_label_)\n",
    "        #plt.plot(xs,ys_avg, 'o', color=cmap(ep_label),alpha=al, markersize=1.2,label=ep_label)\n",
    "        plt.plot(xsmooth,y_smooth_, linewidth=1.45,color=cmap(ep_label),alpha=al)\n",
    "        plt.title('RNN based avg. reward per step',fontsize=fz+2)\n",
    "        plt.xlabel('n. episodes',fontsize=fz)\n",
    "        plt.ylabel('RNN based return',fontsize=fz)\n",
    "        leg=plt.legend(prop={'size': 7}, markerscale=3)\n",
    "        for lh in leg.legendHandles: \n",
    "            lh.set_alpha(1)\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(4.5,3.0)\n",
    "        plt.xticks(np.arange(0,6001,500), fontsize=fz)\n",
    "        plt.yticks(np.arange(-90,0,15),fontsize=fz)\n",
    "        plt.grid(linestyle = '--', linewidth = 0.5)\n",
    "        ax = plt.gca()\n",
    "        ax.set_facecolor((1, 1, 1))\n",
    "        \n",
    "    if(rnn_plots>0):\n",
    "        #plt.legend()\n",
    "        plt.show()\n",
    "    rnn_plots = 0\n",
    "    for ep in ep_lists:\n",
    "        ep_label = ep[2][7:]\n",
    "        if(not \"LSTM\" in ep_label.split('-')):\n",
    "            continue\n",
    "        #print(ep_label)\n",
    "        rnn_plots += 1\n",
    "        ys_avg = []\n",
    "        ys_std = []\n",
    "        ys_hi  = []\n",
    "        ys_lo  = []\n",
    "        xs     = []\n",
    "        k=25\n",
    "        y0 = 0\n",
    "        for i in range(0,len(ep[0]['cpbp_score']),50):\n",
    "            #print([[i,k*np.mean(ep[0]['rnn_score'][max(0,i-5):min(len(ep[0]['rnn_score'])-1,i+5)])]])\n",
    "            if(i<100):\n",
    "                continue\n",
    "            xs     += [i]\n",
    "            if(len(ys_avg)==0):\n",
    "                y0 = k*np.mean(ep[0]['cpbp_score'][max(0,i-25):min(len(ep[0]['cpbp_score'])-1,i+25)])\n",
    "            ys_avg += [k*np.mean(ep[0]['cpbp_score'][max(0,i-25):min(len(ep[0]['cpbp_score'])-1,i+25)])-y0]\n",
    "            ys_std += [k*np.std(ep[0]['cpbp_score'][max(0,i-25):min(len(ep[0]['cpbp_score'])-1,i+25)])]\n",
    "        ys_avg = np.array(ys_avg)\n",
    "        ys_std = np.array(ys_std)\n",
    "        xs     = np.array(xs)\n",
    "        #plt.plot(np.arange(len(ep[0]['rnn_score'])),np.array(ep[0]['rnn_score'])*k, linewidth=0.5,alpha=0.25,color=cmap(ep_label))\n",
    "        #plt.plot(ys_avg[:,0],ys_avg[:,1], linewidth=1.0,color=cmap(ep_label),alpha=0.5)\n",
    "        #plt.plot(ys_avg[:,0],ys_avg[:,1], 'o', color=cmap(ep_label),alpha=1.0, markersize=1.0,label=ep_label)\n",
    "        #plt.errorbar(ys_avg[:,0], ys_avg[:,1], yerr=ys_std, color=cmap(ep_label),alpha=1.0,linewidth=0,elinewidth=1.0,capsize=0)\n",
    "        fz = 7\n",
    "        \n",
    "        ys_hi = ys_avg + ys_std\n",
    "        ys_lo = ys_avg - ys_std\n",
    "        #print(ys_avg)\n",
    "        spl_hi = make_interp_spline(xs, ys_hi, k=1)\n",
    "        \n",
    "        spl_lo = make_interp_spline(xs, ys_lo, k=1)\n",
    "        spl    = make_interp_spline(xs, ys_avg,k=1)\n",
    "        xsmooth = np.linspace(xs.min(), xs.max(), 200) \n",
    "        y_smooth_hi = spl_hi(xsmooth)\n",
    "        y_smooth_lo = spl_lo(xsmooth)\n",
    "        y_smooth_   = spl(xsmooth)\n",
    "        \n",
    "        \n",
    "        ep_label = ep_label.split('-')\n",
    "        ep_label.remove('LSTM')\n",
    "        ep_label_ = copy.deepcopy(ep_label)\n",
    "        real_label = []\n",
    "        if('dV' in ep_label_):\n",
    "            real_label += ['ΔV']\n",
    "        elif('dV.m' in ep_label_):\n",
    "            real_label += ['ΔV.m']\n",
    "        elif('dV.dE' in ep_label_):\n",
    "            real_label += ['ΔV.ΔE']\n",
    "        elif('dV.dE(normalized)' in ep_label_):\n",
    "            real_label += ['ΔV.ΔE.normalized']\n",
    "        elif('dE.m' in ep_label_):\n",
    "            real_label += ['ΔE.m']\n",
    "        elif('dV.dE.m' in ep_label_):\n",
    "            real_label += ['ΔV.ΔE.m']\n",
    "        if('A' in ep_label_):\n",
    "            real_label += ['[A]']\n",
    "        elif('B' in ep_label_):\n",
    "            real_label += ['[B]']\n",
    "        elif('B(normed)' in ep_label_):\n",
    "            real_label += ['[B.normed]']\n",
    "        elif('B(noised)' in ep_label_):\n",
    "            real_label += ['[B.noised]']\n",
    "        elif('C' in ep_label_):\n",
    "            real_label += ['[C]']\n",
    "        ep_label_= '-'.join(real_label)\n",
    "        ep_label = '-'.join(ep_label)\n",
    "        al =0.95\n",
    "        if(ep_label in highlighted_labels):\n",
    "            al=0.95\n",
    "        \n",
    "        plt.fill_between(xsmooth,y_smooth_hi,y_smooth_lo,color=cmap(ep_label),alpha=al/5,linewidth=0.0,label=ep_label_)\n",
    "        #plt.plot(xs,ys_avg, 'o', color=cmap(ep_label),alpha=al, markersize=1.2,label=ep_label)\n",
    "        plt.plot(xsmooth,y_smooth_, linewidth=1.45,color=cmap(ep_label),alpha=al)\n",
    "        plt.title('CP based avg. reward per step',fontsize=fz+2)\n",
    "        plt.xlabel('n. episodes',fontsize=fz)\n",
    "        plt.ylabel('CP based return',fontsize=fz)\n",
    "        leg=plt.legend(prop={'size': 7}, markerscale=3)\n",
    "        for lh in leg.legendHandles: \n",
    "            lh.set_alpha(1)\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(4.5,3.0)\n",
    "        plt.xticks(np.arange(100,6001,500), fontsize=fz)\n",
    "        plt.yticks(np.arange(0,60,15),fontsize=fz)\n",
    "        plt.grid(linestyle = '--', linewidth = 0.5)\n",
    "        ax = plt.gca()\n",
    "        ax.set_facecolor((1, 1, 1))\n",
    "    if(rnn_plots>0):\n",
    "        plt.show()\n",
    "\n",
    "def get_cmap_string(palette='tab10', domain=[]):\n",
    "    domain_unique = np.unique(domain)\n",
    "    hash_table = {key: i_str for i_str, key in enumerate(domain_unique)}\n",
    "    mpl_cmap = plt.cm.get_cmap(palette, lut=len(domain_unique))\n",
    "\n",
    "    def cmap_out(X, **kwargs):\n",
    "        return mpl_cmap(hash_table[X], **kwargs)\n",
    "    return cmap_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#no-marginals-explorer-2-LSTM is the new LSTM version\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "agent_names = []\n",
    "\n",
    "agent_names += [\n",
    "    \"dV.dE-NEW\",\"dV.m-OLD\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "agent_params = {'batch_size':128,\n",
    "                'gamma'     :0.99,\n",
    "                'eps_start' :0.99,\n",
    "                \n",
    "                'eps_end'   :0.10,\n",
    "                'eps_decay' :6500,\n",
    "                'tau'       :0.005,\n",
    "                'lr'        :0.001,\n",
    "                'memory_size':40000,\n",
    "                'name':\"\"}\n",
    "for an in agent_names:\n",
    "    agent_params['name'] = an\n",
    "    agent_ = Agent(**agent_params)\n",
    "    results += [agent_.run_results]\n",
    "plot_violations(results, k=1, agent_names=agent_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
